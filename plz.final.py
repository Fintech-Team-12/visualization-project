import streamlit as st
import pandas as pd
import pydeck as pdk
import json
import plotly.graph_objects as go
from pathlib import Path
import re
import unicodedata
from PIL import Image   
import os 
import plotly.express as px
import numpy as np 



# =========================
# 0) Streamlit ì„¤ì •
# =========================
st.set_page_config(page_title="ë‚´ ì§‘ ë§ˆë ¨ì˜ ê¿ˆ", layout="wide")

# =========================
# 1) ê²½ë¡œ/íŒŒì¼ íƒìƒ‰ (mac í•œê¸€ NFC/NFD ë¬¸ì œ íšŒí”¼)
# =========================
BASE_DIR = Path(__file__).resolve().parent
# BASE_DIR = BASE_DIR + "/data"

def nfc(s: str) -> str:
    return unicodedata.normalize("NFC", s)


files_in_dir = sorted([p.name for p in BASE_DIR.iterdir()])

# âœ… ì•„íŒŒíŠ¸ íŒŒì¼: ì‹œë„_apart_YYYY_data.csv
apt_pat = re.compile(r"^ì‹œë„_apart_(\d{4})_data\.csv$")
apart_files = sorted([str(BASE_DIR / fn) for fn in files_in_dir if apt_pat.match(nfc(fn))])

# âœ… ì†Œë“ íŒŒì¼
WAGE_PATH = str(BASE_DIR / "1ì¸ë‹¹_ê°œì¸ì†Œë“.csv")

if not apart_files:
    st.error(
        "âŒ ì•„íŒŒíŠ¸ ë°ì´í„° íŒŒì¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.\n\n"
        f"ì°¾ëŠ” ìœ„ì¹˜: {BASE_DIR}\n\n"
        "í•„ìš” íŒŒì¼ ì˜ˆì‹œ:\n"
        "  ì‹œë„_apart_2010_data.csv, ì‹œë„_apart_2015_data.csv, ì‹œë„_apart_2020_data.csv, ì‹œë„_apart_2025_data.csv"
    )
    st.stop()

if not Path(WAGE_PATH).exists():
    st.error(
        "âŒ ì†Œë“ ë°ì´í„° íŒŒì¼(1ì¸ë‹¹_ê°œì¸ì†Œë“.csv)ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.\n\n"
        f"ì°¾ëŠ” ìœ„ì¹˜: {BASE_DIR}"
    )
    st.stop()

#ìœ¤ì¬íŒŒíŠ¸=====
# =========================================================
# ğŸ“ (ì¶”ê°€) ì§€ë„ ì‹œê°í™” ì„¹ì…˜: ë²•ì •ë™ ê±°ë˜ëŸ‰ + ê´‘ì—­ì‹œë„ íŠ¸ë Œë“œ
# - âœ… import/set_page_config/BASE_DIR ì¤‘ë³µ ì—†ìŒ
# - âœ… ëª¨ë“  íŒŒì¼ ê²½ë¡œ BASE_DIR ê¸°ì¤€
# - âœ… 'all' íŒŒì¼ ì—†ì´ 2010/2015/2020/2025ë¡œ 'all' ìë™ ìƒì„±(í‰ê· )
# - âœ… ì»¬ëŸ¼ëª… ì˜¤íƒ€/ë¶ˆì¼ì¹˜ ë°©ì–´
# =========================================================

# í•„ìš”í•œ ëª¨ë“ˆì€ ê¸°ì¤€ ì½”ë“œ ìƒë‹¨ importì— ì¶”ê°€ë˜ì–´ ìˆì–´ì•¼ í•¨:
#   import pydeck as pdk
#   import json

# -------------------------
# 0) ê³µí†µ ìœ í‹¸
# -------------------------
def _get_color_by_volume(val: int, max_val: int):
    """ê±°ë˜ëŸ‰ì´ ë§ì„ìˆ˜ë¡ ì§„í•œ ë¹¨ê°•"""
    if max_val <= 0:
        return [255, 255, 200, 200]
    ratio = float(val) / float(max_val)
    ratio = max(0.0, min(1.0, ratio))
    g = int(255 * (1 - ratio))
    b = int(100 * (1 - ratio))
    return [255, g, b, 200]


# =========================================================
# 1) ë²•ì •ë™ë³„ ê±°ë˜ëŸ‰ (ColumnLayer)
# =========================================================
# =========================================================
# âš™ï¸ ì§€ë„ ì‹œê°í™” ì„¤ì • (ë³¸ë¬¸ ìƒë‹¨ì— ë°°ì¹˜)
# =========================================================
st.title("ğŸ’¸ ë‚´ ì§‘ ë§ˆë ¨ì˜ ê¿ˆ ğŸ’¸")

st.markdown("---")

st.subheader("ğŸ“Š ë¶€ë™ì‚° ê±°ë˜ëŸ‰ ëŒ€ì‹œë³´ë“œ")
st.markdown("#### âš™ï¸ ì§€ë„ ì‹œê°í™” ì„¤ì • ####")
view_option = st.radio(
    "ë³´ê³  ì‹¶ì€ ë°ì´í„°ë¥¼ ì„ íƒí•˜ì„¸ìš”:",
    ("ê±°ë˜ ê¸ˆì•¡ ì¤‘ì•™ê°’ (ë‹¨ìœ„: ë§Œì›)", "í‰ë‹¹ ê°€ê²© ì¤‘ì•™ê°’ (ë‹¨ìœ„: ë§Œì›)"),
    horizontal=True,
    key="map_view_option"
)

st.subheader("ğŸ“ ë²•ì •ë™ë³„ ìƒì„¸ ê±°ë˜ëŸ‰")
st.write("2010ë…„, 2015ë…„, 2020ë…„, 2025ë…„ ì§€ì—­ë³„ ì•„íŒŒíŠ¸ ê±°ë˜ëŸ‰ì˜ í•©")

@st.cache_data(show_spinner=True)
def load_dong_data_map(base_dir_str: str) -> pd.DataFrame:
    base_dir = Path(base_dir_str)
    path = base_dir / "ë²•ì •ë™ì£¼ì†Œ ê±°ë˜ëŸ‰ ë°ì´í„°.csv"
    if not path.exists():
        raise FileNotFoundError(f"'{path.name}' íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ìœ„ì¹˜: {base_dir}")

    df = pd.read_csv(path)

    # ì»¬ëŸ¼ í›„ë³´(ì˜¤íƒ€/ë³€í˜• ëŒ€ì‘)
    col_lng = next((c for c in ["Longitude", "longitude", "lng", "LNG"] if c in df.columns), None)
    col_lat = next((c for c in ["Latitude", "latitude", "lat", "LAT"] if c in df.columns), None)
    col_name = next((c for c in ["ë²•ì •ë™ì£¼ì†Œ", "dong_name", "ë™", "ë²•ì •ë™"] if c in df.columns), None)
    col_vol = next((c for c in ["ì§€ì—­ë³„ ê±°ë˜ëŸ‰", "ì§€ì—­ë³„ ê²¨ë˜ëŸ‰", "ê±°ë˜ëŸ‰", "volume", "VOL"] if c in df.columns), None)

    missing = [k for k, v in {"lng": col_lng, "lat": col_lat, "dong_name": col_name, "volume": col_vol}.items() if v is None]
    if missing:
        raise ValueError(
            "ë²•ì •ë™ ê±°ë˜ëŸ‰ CSV ì»¬ëŸ¼ì„ ì¸ì‹í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.\n"
            f"- ëˆ„ë½ í‚¤: {missing}\n"
            f"- ê°ì§€ëœ ì»¬ëŸ¼: {list(df.columns)}\n"
            "í•„ìš” ì˜ˆì‹œ: Longitude, Latitude, ë²•ì •ë™ì£¼ì†Œ, ì§€ì—­ë³„ ê±°ë˜ëŸ‰"
        )

    df = df.rename(columns={col_lng: "lng", col_lat: "lat", col_name: "dong_name", col_vol: "volume"})

    df["volume"] = pd.to_numeric(df["volume"], errors="coerce").fillna(0).astype(int)
    df["lng"] = pd.to_numeric(df["lng"], errors="coerce")
    df["lat"] = pd.to_numeric(df["lat"], errors="coerce")

    df = df.dropna(subset=["lng", "lat"])
    return df


try:
    df_dong = load_dong_data_map(str(BASE_DIR))
    max_vol_dong = int(df_dong["volume"].max()) if not df_dong.empty else 0

    df_dong["bar_width"] = 0 if max_vol_dong == 0 else ((df_dong["volume"] / max_vol_dong) * 100).astype(int)
    df_dong["color"] = df_dong["volume"].apply(lambda x: _get_color_by_volume(int(x), max_vol_dong))

    tooltip_dong = {
        "html": """
            <div style="background: rgba(20, 20, 20, 0.95); padding: 12px; border-radius: 8px; color: white;
                        font-family: 'Segoe UI', sans-serif; box-shadow: 0 4px 6px rgba(0,0,0,0.3); min-width: 180px;">
                <div style="font-weight: bold; font-size: 1.1em; border-bottom: 1px solid #555;
                            margin-bottom: 8px; padding-bottom: 4px; color: #fff;">
                    ğŸ“ {dong_name}
                </div>

                <div style="display: flex; justify-content: space-between; align-items: center; margin-bottom: 6px;">
                    <span style="font-size: 0.9em; color: #ccc;">ì´ ê±°ë˜ëŸ‰</span>
                    <span style="font-weight: bold; font-size: 1.1em; color: #ff9f1c;">
                        {volume} <span style="font-size:0.7em; color:#aaa;">ê±´</span>
                    </span>
                </div>

                <div style="width: 100%; background-color: #444; height: 10px; border-radius: 5px;
                            overflow: hidden; margin-bottom: 2px;">
                    <div style="width: {bar_width}%; background: linear-gradient(90deg, #ff9f1c, #ff5e00);
                                height: 100%;"></div>
                </div>

                <div style="text-align: right; font-size: 11px; color: #777;">
                    Max ëŒ€ë¹„ {bar_width}% ìˆ˜ì¤€
                </div>
            </div>
        """,
        "style": {"color": "white"}
    }

    layer_dong = pdk.Layer(
        "ColumnLayer",
        data=df_dong,
        get_position=["lng", "lat"],
        get_elevation="volume",
        elevation_scale=7,
        radius=300,
        extruded=True,
        get_fill_color="color",
        pickable=True,
        auto_highlight=True,
    )

    view_state_dong = pdk.ViewState(
        longitude=127.5,
        latitude=36.0,
        zoom=6.5,
        pitch=45,
        bearing=0
    )

    r_dong = pdk.Deck(
        layers=[layer_dong],
        initial_view_state=view_state_dong,
        tooltip=tooltip_dong,
        map_style=pdk.map_styles.DARK
    )

    st.pydeck_chart(r_dong)

except Exception as e:
    st.error("âŒ ë²•ì •ë™ ê±°ë˜ëŸ‰ ì§€ë„ ë¡œë”© ì‹¤íŒ¨")
    st.exception(e)


# =========================================================
# 2) ê´‘ì—­ìì¹˜ë‹¨ì²´ íŠ¸ë Œë“œ (GeoJsonLayer)
#   - 'all' íŒŒì¼ ì—†ì´ ìë™ ìƒì„±(2010/2015/2020/2025 í‰ê· )
# =========================================================
st.markdown("---")

def round_coordinates(coords, precision=4):
    if not coords:
        return coords
    if isinstance(coords[0], (int, float)):
        return [round(c, precision) for c in coords]
    return [round_coordinates(c, precision) for c in coords]


@st.cache_data(show_spinner=True)
def load_geo_data_map(base_dir_str: str) -> dict:
    base_dir = Path(base_dir_str)
    geo_path = base_dir / "ëŒ€í•œë¯¼êµ­_ê´‘ì—­ìì¹˜ë‹¨ì²´_ê²½ê³„ (1).geojson"
    if not geo_path.exists():
        raise FileNotFoundError(f"'{geo_path.name}' íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ìœ„ì¹˜: {base_dir}")

    with open(geo_path, encoding="utf-8") as f:
        geojson = json.load(f)

    # ì¢Œí‘œ ë‹¨ìˆœí™”(ì„±ëŠ¥ ê°œì„ )
    for feature in geojson.get("features", []):
        geom = feature.get("geometry", {})
        if "coordinates" in geom:
            geom["coordinates"] = round_coordinates(geom["coordinates"])
    return geojson


@st.cache_data(show_spinner=True)
def load_apart_data_map(base_dir_str: str) -> dict:
    """
    apart_dict[year] = ì‹œë„ë³„ ë°ì´í„° (ì¤‘ë³µ ì œê±°)
    apart_dict['all'] = 2010/2015/2020/2025 í‰ê· ìœ¼ë¡œ ìƒì„±
    """
    base_dir = Path(base_dir_str)
    years = [2010, 2015, 2020, 2025]
    apart_dict = {}

    usecols = ["ì‹œë„", "ì‹œë„ë³„_ê±°ë˜ê¸ˆì•¡_ì¤‘ì•™ê°’", "ì‹œë„ë³„_í‰ë‹¹ê°€ê²©_ì¤‘ì•™ê°’"]

    for y in years:
        path = base_dir / f"ì‹œë„_apart_{y}_data.csv"
        if not path.exists():
            apart_dict[y] = pd.DataFrame()
            continue

        df = pd.read_csv(path, usecols=[c for c in usecols if c in pd.read_csv(path, nrows=0).columns])
        # ì»¬ëŸ¼ ìœ íš¨ì„± ì²´í¬
        if "ì‹œë„" not in df.columns:
            apart_dict[y] = pd.DataFrame()
            continue

        # í›„ë³´ ì»¬ëŸ¼ ë³´ê°•(ë§Œì•½ ì¤‘ì•™ê°’ ì»¬ëŸ¼ëª…ì´ ë‹¤ë¥´ë©´ ì—¬ê¸°ì„œ ì¶”ê°€ ëŒ€ì‘ ê°€ëŠ¥)
        if "ì‹œë„ë³„_ê±°ë˜ê¸ˆì•¡_ì¤‘ì•™ê°’" not in df.columns or "ì‹œë„ë³„_í‰ë‹¹ê°€ê²©_ì¤‘ì•™ê°’" not in df.columns:
            apart_dict[y] = pd.DataFrame()
            continue

        df = df.drop_duplicates(subset=["ì‹œë„"])
        # ìˆ«ìí™”
        df["ì‹œë„ë³„_ê±°ë˜ê¸ˆì•¡_ì¤‘ì•™ê°’"] = pd.to_numeric(df["ì‹œë„ë³„_ê±°ë˜ê¸ˆì•¡_ì¤‘ì•™ê°’"], errors="coerce")
        df["ì‹œë„ë³„_í‰ë‹¹ê°€ê²©_ì¤‘ì•™ê°’"] = pd.to_numeric(df["ì‹œë„ë³„_í‰ë‹¹ê°€ê²©_ì¤‘ì•™ê°’"], errors="coerce")
        apart_dict[y] = df

    # 'all' ìƒì„±: ì—°ë„ë³„ dfë¥¼ concat í›„ ì‹œë„ë³„ í‰ê· (0 ì œì™¸ í‰ê· ì€ ì›í•˜ë©´ ë°”ê¿€ ìˆ˜ ìˆìŒ)
    frames = []
    for y in years:
        dfy = apart_dict.get(y, pd.DataFrame())
        if not dfy.empty:
            tmp = dfy[["ì‹œë„", "ì‹œë„ë³„_ê±°ë˜ê¸ˆì•¡_ì¤‘ì•™ê°’", "ì‹œë„ë³„_í‰ë‹¹ê°€ê²©_ì¤‘ì•™ê°’"]].copy()
            tmp["year"] = y
            frames.append(tmp)

    if frames:
        all_df = pd.concat(frames, ignore_index=True)
        # ì‹œë„ë³„ í‰ê· 
        all_df = all_df.groupby("ì‹œë„", as_index=False)[["ì‹œë„ë³„_ê±°ë˜ê¸ˆì•¡_ì¤‘ì•™ê°’", "ì‹œë„ë³„_í‰ë‹¹ê°€ê²©_ì¤‘ì•™ê°’"]].mean()
        apart_dict["all"] = all_df
    else:
        apart_dict["all"] = pd.DataFrame()

    return apart_dict


@st.cache_data(show_spinner=True)
def process_map_data_map(geojson: dict, apart_dict: dict) -> pd.DataFrame:
    regions = [f["properties"]["CTP_KOR_NM"] for f in geojson.get("features", [])]
    df_map = pd.DataFrame({"ì‹œë„": regions})

    years = [2010, 2015, 2020, 2025, "all"]
    for y in years:
        df_year = apart_dict.get(y, pd.DataFrame())
        if df_year is None or df_year.empty:
            continue

        temp = df_year[["ì‹œë„", "ì‹œë„ë³„_ê±°ë˜ê¸ˆì•¡_ì¤‘ì•™ê°’", "ì‹œë„ë³„_í‰ë‹¹ê°€ê²©_ì¤‘ì•™ê°’"]].copy()
        temp = temp.rename(columns={
            "ì‹œë„ë³„_ê±°ë˜ê¸ˆì•¡_ì¤‘ì•™ê°’": f"median_price_{y}",
            "ì‹œë„ë³„_í‰ë‹¹ê°€ê²©_ì¤‘ì•™ê°’": f"pyeong_price_{y}",
        })
        df_map = pd.merge(df_map, temp, on="ì‹œë„", how="left")

    # ê²°ì¸¡ì€ 0
    for c in df_map.columns:
        if c != "ì‹œë„":
            df_map[c] = pd.to_numeric(df_map[c], errors="coerce").fillna(0).astype(int)
    return df_map


def get_fill_color_map(val: int, min_val: int, max_val: int):
    if val == 0:
        return [50, 50, 50, 150]
    if max_val <= min_val:
        return [100, 100, 100, 150]

    ratio = (val - min_val) / (max_val - min_val)
    ratio = max(0.0, min(1.0, ratio))
    r = 255
    g = int(255 * (1 - ratio))
    b = 0
    return [r, g, b, 200]


def generate_svg_chart_map(prices):
    width, height = 220, 80
    p_min, p_max = min(prices), max(prices)
    if p_min == p_max:
        p_max += 10

    def get_x(i): return 20 + (i / 3) * (width - 40)
    def get_y(p): return height - 20 - ((p - p_min) / (p_max - p_min) * (height - 40))

    points = " ".join([f"{get_x(i)},{get_y(p)}" for i, p in enumerate(prices)])

    elements = ""
    for i, p in enumerate(prices):
        cx, cy = get_x(i), get_y(p)
        elements += f'<circle cx="{cx}" cy="{cy}" r="3" fill="white" stroke="#d32f2f" stroke-width="2"/>'
        elements += f'<text x="{cx}" y="{cy-8}" fill="white" font-size="10" text-anchor="middle" font-weight="bold">{p}</text>'

    return (
        f'<svg width="{width}" height="{height}" style="background: rgba(0,0,0,0);">'
        f'<text x="{get_x(0)}" y="{height-5}" fill="#aaa" font-size="10" text-anchor="middle">2010</text>'
        f'<text x="{get_x(1)}" y="{height-5}" fill="#aaa" font-size="10" text-anchor="middle">2015</text>'
        f'<text x="{get_x(2)}" y="{height-5}" fill="#aaa" font-size="10" text-anchor="middle">2020</text>'
        f'<text x="{get_x(3)}" y="{height-5}" fill="#aaa" font-size="10" text-anchor="middle">2025</text>'
        f'<polyline points="{points}" fill="none" stroke="#d32f2f" stroke-width="2"/>'
        f'{elements}</svg>'
    )


@st.cache_data(show_spinner=True)
def precompute_visual_assets_map(base_dir_str: str):
    apart_dict = load_apart_data_map(base_dir_str)
    geojson_data = load_geo_data_map(base_dir_str)

    if not geojson_data.get("features"):
        return None, {}

    df_map = process_map_data_map(geojson_data, apart_dict)
    price_dict = df_map.set_index("ì‹œë„").to_dict("index")

    stats = {}
    for prefix in ["median_price", "pyeong_price"]:
        col = f"{prefix}_all"
        vals = df_map[df_map[col] > 0][col]
        stats[prefix] = (int(vals.min()), int(vals.max())) if not vals.empty else (0, 100)

    assets_cache = {}
    for region_name, row in price_dict.items():
        assets_cache[region_name] = {}
        for prefix in ["median_price", "pyeong_price"]:
            p_prices = [int(row.get(f"{prefix}_{y}", 0)) for y in [2010, 2015, 2020, 2025]]
            p_val = int(row.get(f"{prefix}_all", 0))
            p_min, p_max = stats[prefix]

            assets_cache[region_name][prefix] = {
                "value": p_val,
                "color": get_fill_color_map(p_val, p_min, p_max),
                "chart": generate_svg_chart_map(p_prices)
            }

    return geojson_data, assets_cache


if "ê±°ë˜ ê¸ˆì•¡ ì¤‘ì•™ê°’" in view_option:
    target_prefix = "median_price"
    chart_title = "ê±°ë˜ ê¸ˆì•¡ ì¤‘ì•™ê°’"
else:
    target_prefix = "pyeong_price"
    chart_title = "í‰ë‹¹ ê°€ê²© ì¤‘ì•™ê°’"

st.subheader(f"ğŸ“‰ 17ê°œ ì‹œë„ ì•„íŒŒíŠ¸ {chart_title} íŠ¸ë Œë“œ (2010, 2015, 2020, 2025)")
st.markdown("ì§€ë„ ìƒ‰ìƒì€ **4ê°œë…„ í‰ê· (all)** ê¸°ì¤€ì´ë©°, íˆ´íŒì€ **ì—°ë„ë³„ ë³€í™”**ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.")

try:
    geojson_data, assets_cache = precompute_visual_assets_map(str(BASE_DIR))

    if geojson_data and assets_cache:
        for feature in geojson_data["features"]:
            region_name = feature["properties"]["CTP_KOR_NM"]

            if region_name in assets_cache:
                data = assets_cache[region_name][target_prefix]
                feature["properties"]["current_value"] = data["value"]
                feature["properties"]["fill_color"] = data["color"]
                feature["properties"]["svg_chart"] = data["chart"]
                feature["properties"]["chart_title"] = chart_title
            else:
                feature["properties"]["current_value"] = 0
                feature["properties"]["fill_color"] = [50, 50, 50, 150]
                feature["properties"]["svg_chart"] = ""

        layer = pdk.Layer(
            "GeoJsonLayer",
            geojson_data,
            pickable=True,
            stroked=True,
            filled=True,
            extruded=False,
            get_fill_color="properties.fill_color",
            get_line_color=[255, 255, 255, 100],
            line_width_min_pixels=1,
            auto_highlight=True,
        )

        tooltip = {
            "html": """
            <div style="background: rgba(0, 0, 0, 0.85); padding: 15px; border-radius: 10px; color: white;
                        font-family: sans-serif; box-shadow: 0 4px 6px rgba(0,0,0,0.3);">
                <div style="font-weight: bold; font-size: 16px; margin-bottom: 5px; border-bottom: 1px solid #555; padding-bottom: 5px;">
                    ğŸ“ {CTP_KOR_NM}
                </div>
                <div style="font-size: 12px; color: #ccc; margin-bottom: 10px;">
                    4ê°œë…„ í‰ê· (all) ê¸°ì¤€:
                    <span style="color: #ffeb3b; font-weight: bold; font-size: 14px;">{current_value}</span> ë§Œì›
                </div>
                <div style="background: rgba(255,255,255,0.05); border-radius: 5px; padding: 5px;">
                    {svg_chart}
                </div>
            </div>
            """,
            "style": {"color": "white"}
        }

        view_state = pdk.ViewState(longitude=127.5, latitude=36.0, zoom=6, pitch=0)

        r = pdk.Deck(
            layers=[layer],
            initial_view_state=view_state,
            tooltip=tooltip,
            map_style=pdk.map_styles.DARK
        )

        st.pydeck_chart(r, width="stretch", height=700)

    else:
        st.error("ì§€ë„ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. (geojson ë˜ëŠ” ìì‚° ìºì‹œê°€ ë¹„ì–´ ìˆìŒ)")

except Exception as e:
    st.error("âŒ ê´‘ì—­ì‹œë„ ì§€ë„ ë¡œë”© ì‹¤íŒ¨")
    st.exception(e)



st.markdown("---")


# =========================
# 2) íƒ€ì´í‹€
# =========================
st.subheader("ğŸ“Œ ì•„íŒŒíŠ¸ ê°€ê²© ìƒìŠ¹ ì¶”ì„¸")

# =========================
# 3) ìŠ¤íƒ€ì¼(ìš”ì²­ ë°˜ì˜: ë¸”ë™+ë¸”ë£¨ / ì„  ë‘ê»˜)
# =========================
BLACK = "#444444"
BLUE = "#74a7fe"
LINE_W_THICK = 4   # êµ¬ë§¤ê°€ëŠ¥/ê°œì›” ê·¸ë˜í”„ ì„  ë‘ê»˜
LINE_W_NORMAL = 4  # ì§€ìˆ˜/ë¤ë²¨ ì„  ë‘ê»˜

# =========================
# 4) ìœ í‹¸
# =========================
def pick_col(df: pd.DataFrame, candidates: list[str]) -> str | None:
    for c in candidates:
        if c in df.columns:
            return c
    return None

def make_index(series: pd.Series, years: pd.Series, base_year: int = 2010) -> pd.Series:
    mask = years == base_year
    if mask.sum() == 0:
        raise ValueError(f"ê¸°ì¤€ì—°ë„({base_year})ê°€ ë°ì´í„°ì— ì—†ìŠµë‹ˆë‹¤. ê°€ëŠ¥í•œ ì—°ë„: {sorted(years.unique().tolist())}")
    base = series[mask].iloc[0]
    return (series / base) * 100.0

# =========================
# 5) ë¡œë”© í•¨ìˆ˜ (ìºì‹œëŠ” "ìœ„ì ¯ ì—†ëŠ”" ìˆœìˆ˜ í•¨ìˆ˜ë§Œ)
# =========================
@st.cache_data(show_spinner=True)
def load_wage_raw(path: str) -> pd.DataFrame:
    df = pd.read_csv(path)
    if "Unnamed: 0" in df.columns:
        df = df.drop(columns=["Unnamed: 0"])
    return df

def prepare_wage_df(wage_raw: pd.DataFrame, item_choice: str, hh_choice: str) -> pd.DataFrame:
    year_col = "Year" if "Year" in wage_raw.columns else ("year" if "year" in wage_raw.columns else None)
    if year_col is None:
        raise ValueError(f"ì†Œë“ ë°ì´í„°ì— Year/year ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤. í˜„ì¬ ì»¬ëŸ¼: {list(wage_raw.columns)}")

    required = {"item", "hh", "value"}
    if not required.issubset(set(wage_raw.columns)):
        raise ValueError(f"ì†Œë“ ë°ì´í„°ì— item/hh/value ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤. í˜„ì¬ ì»¬ëŸ¼: {list(wage_raw.columns)}")

    out = wage_raw.copy()
    out = out[out["item"] == item_choice]
    out = out[out["hh"] == hh_choice]

    out[year_col] = pd.to_numeric(out[year_col], errors="coerce")
    out["value"] = pd.to_numeric(out["value"], errors="coerce")
    out = out.dropna(subset=[year_col, "value"])

    out = out.rename(columns={year_col: "year", "value": "income_value"})
    out["year"] = out["year"].astype(int)

    out = out.groupby("year", as_index=False)["income_value"].mean()
    return out.sort_values("year").reset_index(drop=True)

@st.cache_data(show_spinner=True)
def load_apart_auto(apart_paths: list[str]) -> pd.DataFrame:
    """
    ì „êµ­ ëŒ€í‘œ í‰ë‹¹ê°€ê²© = (ì‹œë„ë³„ í‰ë‹¹ê°€ê²©) ì„ (ì‹œë„ë³„ ì´ ê±°ë˜ê¸ˆì•¡)ìœ¼ë¡œ ê°€ì¤‘í‰ê· 
    - price_col ìš°ì„ : ì‹œë„ë³„_í‰ë‹¹ê°€ê²©_ì¤‘ì•™ê°’, ê·¸ ë‹¤ìŒ ì‹œë„ë³„_í‰ê· _í‰ë‹¹ê°€ê²©
    - weight_col ìš°ì„ : ì‹œë„ë³„_ì´_ê±°ë˜ê¸ˆì•¡
    """
    rows = []
    for p in sorted(apart_paths):
        name = nfc(Path(p).name)
        m = re.search(r"^ì‹œë„_apart_(\d{4})_data\.csv$", name)
        if not m:
            continue
        year = int(m.group(1))

        df = pd.read_csv(p)

        # âœ… ê°€ê²© ì»¬ëŸ¼ í›„ë³´(ë„ˆ ë°ì´í„° ê¸°ì¤€)
        price_col = pick_col(df, [
            "ì‹œë„ë³„_í‰ë‹¹ê°€ê²©_ì¤‘ì•™ê°’",
            "ì‹œë„ë³„_í‰ê· _í‰ë‹¹ê°€ê²©",
            "ì‹œë„ë³„_í‰ë‹¹ê°€ê²©ì¤‘ì•™ê°’",
            "ì‹œë„ë³„_í‰ê· í‰ë‹¹ê°€ê²©",
        ])

        # âœ… ê°€ì¤‘ì¹˜(ê±°ë˜ê¸ˆì•¡) ì»¬ëŸ¼ í›„ë³´
        weight_col = pick_col(df, [
            "ì‹œë„ë³„_ì´_ê±°ë˜ê¸ˆì•¡",
            "ì‹œë„ë³„_ì´ê±°ë˜ê¸ˆì•¡",
            "ì´_ê±°ë˜ê¸ˆì•¡",
            "ì´ê±°ë˜ê¸ˆì•¡",
        ])

        if price_col is None:
            raise ValueError(
                f"{Path(p).name} ì—ì„œ 'í‰ë‹¹ê°€ê²©' ì»¬ëŸ¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.\n"
                f"- ê°ì§€ëœ ì»¬ëŸ¼: {list(df.columns)}\n"
                "í•„ìš” í›„ë³´: ì‹œë„ë³„_í‰ë‹¹ê°€ê²©_ì¤‘ì•™ê°’ / ì‹œë„ë³„_í‰ê· _í‰ë‹¹ê°€ê²©"
            )

        if weight_col is None:
            raise ValueError(
                f"{Path(p).name} ì—ì„œ 'ì´ ê±°ë˜ê¸ˆì•¡(ê°€ì¤‘ì¹˜)' ì»¬ëŸ¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.\n"
                f"- ê°ì§€ëœ ì»¬ëŸ¼: {list(df.columns)}\n"
                "í•„ìš” í›„ë³´: ì‹œë„ë³„_ì´_ê±°ë˜ê¸ˆì•¡"
            )

        price = pd.to_numeric(df[price_col], errors="coerce")
        w = pd.to_numeric(df[weight_col], errors="coerce")

        tmp = pd.DataFrame({"price": price, "w": w}).dropna()
        tmp = tmp[tmp["w"] > 0]

        if tmp.empty:
            raise ValueError(
                f"{Path(p).name}: ê°€ì¤‘í‰ê·  ê³„ì‚°ìš© ë°ì´í„°ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.\n"
                f"price_col={price_col}, weight_col={weight_col}"
            )

        # âœ… ê±°ë˜ê¸ˆì•¡ ê°€ì¤‘í‰ê· 
        weighted_avg = float((tmp["price"] * tmp["w"]).sum() / tmp["w"].sum())

        rows.append({
            "year": year,
            "apt_price_median": weighted_avg,          # (ì´ë¦„ì€ ê·¸ëŒ€ë¡œ ì“°ë˜ ì˜ë¯¸ëŠ” ê°€ì¤‘í‰ê· )
            "apt_price_col_used": price_col,
            "apt_weight_col_used": weight_col
        })

    out = pd.DataFrame(rows).sort_values("year").reset_index(drop=True)
    if out.empty:
        raise ValueError("ì•„íŒŒíŠ¸ íŒŒì¼ì—ì„œ ì—°ë„ë³„ ì§‘ê³„ë¥¼ ë§Œë“¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
    return out

# =========================
# 6) ì†Œë“ ë°ì´í„°: ìœ„ì ¯ ì„ íƒ (ìºì‹œ ë°–)
# =========================
try:
    wage_raw = load_wage_raw(WAGE_PATH)
except Exception as e:
    st.error("âŒ ì†Œë“ íŒŒì¼ ë¡œë”© ì‹¤íŒ¨")
    st.exception(e)
    st.stop()

items = sorted(wage_raw["item"].dropna().unique())
hhs = sorted(wage_raw["hh"].dropna().unique())

default_hh_idx = hhs.index("1ì¸") if "1ì¸" in hhs else 0
default_item_idx = 0

col1, col2 = st.columns(2)
with col1:
    item_choice = st.selectbox("ì†Œë“ í•­ëª© ì„ íƒ", items, index=default_item_idx)
with col2:
    hh_choice = st.selectbox("ê°€êµ¬ìœ í˜• ì„ íƒ", hhs, index=default_hh_idx)

try:
    wage_df = prepare_wage_df(wage_raw, item_choice=item_choice, hh_choice=hh_choice)
except Exception as e:
    st.error("âŒ ì†Œë“ ë°ì´í„° ì²˜ë¦¬ ì‹¤íŒ¨")
    st.exception(e)
    st.stop()

# =========================
# 7) ì•„íŒŒíŠ¸ ë°ì´í„° ë¡œë”©
# =========================
try:
    apt_df = load_apart_auto(apart_files)
except Exception as e:
    st.error("âŒ ì•„íŒŒíŠ¸ ë°ì´í„° ë¡œë”© ì‹¤íŒ¨")
    st.exception(e)
    st.stop()

# =========================
# 8) ë³‘í•© + ì§€ìˆ˜í™”
# =========================
merged = pd.merge(wage_df, apt_df, on="year", how="inner").sort_values("year").reset_index(drop=True)
if merged.empty:
    st.error("âŒ ì†Œë“ ì—°ë„ì™€ ì•„íŒŒíŠ¸ ì—°ë„ê°€ ê²¹ì¹˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
    st.write("ì†Œë“ ì—°ë„:", wage_df["year"].tolist())
    st.write("ì•„íŒŒíŠ¸ ì—°ë„:", apt_df["year"].tolist())
    st.stop()

try:
    merged["Income_Index"] = make_index(merged["income_value"], merged["year"], base_year=2010)
    merged["Apartment_Index"] = make_index(merged["apt_price_median"], merged["year"], base_year=2010)
except Exception as e:
    st.error("âŒ ì§€ìˆ˜í™”(2010=100) ì‹¤íŒ¨")
    st.exception(e)
    st.stop()

df = merged.rename(columns={"year": "Year"}).copy()

latest_year = int(df["Year"].iloc[-1])
gap_2010 = float(df.loc[df["Year"] == 2010, "Apartment_Index"].iloc[0] - df.loc[df["Year"] == 2010, "Income_Index"].iloc[0])
gap_latest = float(df["Apartment_Index"].iloc[-1] - df["Income_Index"].iloc[-1])

st.success(
    f"âœ… ë³‘í•© ì™„ë£Œ: {df['Year'].min()} ~ {df['Year'].max()} (ê¸°ì¤€ì—°ë„=2010=100)\n\n"
    f"- ì†Œë“ ì„ íƒ: {item_choice}, ê°€êµ¬ì› ìˆ˜: {hh_choice}\n"
    f"- ì•„íŒŒíŠ¸ ê°€ê²© ì»¬ëŸ¼: {', '.join(df['apt_price_col_used'].unique())}\n"
    f"- ì•„íŒŒíŠ¸ ëŒ€í‘œê°’: ì‹œë„ë³„ í‰ë‹¹ê°€ê²©ì„ 'ì´ ê±°ë˜ê¸ˆì•¡'ìœ¼ë¡œ ê°€ì¤‘í‰ê· (ì „êµ­ ëŒ€í‘œ)"
)

st.markdown(
    f"""
- 2010ë…„ ê¸°ì¤€ ê²©ì°¨(ì•„íŒŒíŠ¸-ì†Œë“): **{gap_2010:.1f}p**
- {latest_year}ë…„ ê²©ì°¨(ì•„íŒŒíŠ¸-ì†Œë“): **{gap_latest:.1f}p**
"""
)

st.divider()

# =========================
# 9) (1) ì§€ìˆ˜ ì˜ì—­ ì°¨íŠ¸ (ë¸”ë™ + ë¸”ë£¨)
# =========================
st.subheader(" ğŸ“ˆ ì†Œë“ vs ì•„íŒŒíŠ¸ ê°€ê²© ì§€ìˆ˜ (2010=100)")

fig = go.Figure()
fig.add_trace(go.Scatter(
    x=df["Year"], y=df["Income_Index"],
    mode="lines+markers",
    name="ì†Œë“ ì§€ìˆ˜",
    line=dict(color=BLUE, width=LINE_W_NORMAL),
    marker=dict(size=9, color=BLUE),
    fill="tozeroy",
    fillcolor="rgba(31,119,180,0.10)"
))
fig.add_trace(go.Scatter(
    x=df["Year"], y=df["Apartment_Index"],
    mode="lines+markers",
    name="ì•„íŒŒíŠ¸ ê°€ê²© ì§€ìˆ˜",
    line=dict(color=BLACK, width=LINE_W_NORMAL),
    marker=dict(size=9, color=BLACK),
    fill="tonexty",
    fillcolor="rgba(17,17,17,0.10)"
))
fig.update_layout(
    title="ì—°ë„ë³„ ì†Œë“ vs ì•„íŒŒíŠ¸ ê°€ê²© ì§€ìˆ˜ (2010=100)",
    xaxis_title="ì—°ë„",
    yaxis_title="ì§€ìˆ˜",
    hovermode="x unified",
    height=520
)
st.plotly_chart(fig, use_container_width=True)

st.info(
    " **ì§€ìˆ˜ëŠ” 2010ë…„ì„ ê¸°ì¤€ì—°ë„ë¡œ ì„¤ì •í•˜ì—¬ 2025ë…„ê¹Œì§€ì˜ ë³€í™”ë¥¼ ë‚˜íƒ€ëƒ„** "
)

st.divider()

# =========================
# 10) (2) ë¤ë²¨ ì°¨íŠ¸ (ë¸”ë™ + ë¸”ë£¨)
# =========================
st.subheader(" ğŸ‹ï¸ ë¤ë²¨ ì°¨íŠ¸: ì—°ë„ë³„ ê²©ì°¨(ì•„íŒŒíŠ¸-ì†Œë“)")

ddf = df.copy()
ddf["Year_str"] = ddf["Year"].astype(str)

fig2 = go.Figure()

# ì—°ê²°ì„ (ë¤ë²¨ ë°”) - ë¸”ë™
for i in range(len(ddf)):
    fig2.add_shape(
        type="line",
        x0=float(ddf.loc[i, "Income_Index"]), y0=ddf.loc[i, "Year_str"],
        x1=float(ddf.loc[i, "Apartment_Index"]), y1=ddf.loc[i, "Year_str"],
        line=dict(color=BLACK, width=6)
    )

# ì†Œë“ ì (ë¸”ë£¨)
fig2.add_trace(go.Scatter(
    x=ddf["Income_Index"], y=ddf["Year_str"],
    mode="markers",
    name="ì†Œë“ ì§€ìˆ˜",
    marker=dict(size=12, color=BLUE),
    hovertemplate="ì—°ë„: %{y}<br>ì†Œë“ ì§€ìˆ˜: %{x:.1f}<extra></extra>"
))

# ì•„íŒŒíŠ¸ ì (ë¸”ë™)
fig2.add_trace(go.Scatter(
    x=ddf["Apartment_Index"], y=ddf["Year_str"],
    mode="markers",
    name="ì•„íŒŒíŠ¸ ê°€ê²© ì§€ìˆ˜",
    marker=dict(size=12, color=BLACK),
    hovertemplate="ì—°ë„: %{y}<br>ì•„íŒŒíŠ¸ ì§€ìˆ˜: %{x:.1f}<extra></extra>"
))

fig2.update_layout(
    title="ì—°ë„ë³„ ì†Œë“ vs ì•„íŒŒíŠ¸ ê°€ê²© ì§€ìˆ˜ ê²©ì°¨ (ë¤ë²¨)",
    xaxis_title="ì§€ìˆ˜(2010=100)",
    yaxis_title="ì—°ë„",
    height=560,
    margin=dict(l=90, r=40, t=90, b=50),
    hovermode="closest",
    legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="right", x=1)
)
st.plotly_chart(fig2, use_container_width=True)

st.info(f" **ê²©ì°¨(ì§€ìˆ˜): 2010ë…„ {gap_2010:.1f} â†’ {latest_year}ë…„ {gap_latest:.1f}**")

st.divider()

# =========================
# 11) (3) êµ¬ë§¤ê°€ëŠ¥ ë©´ì (í‰) + 1í‰ êµ¬ë§¤ì— í•„ìš”í•œ 'ê°œì›”' ì„¤ëª… ì •ë¦¬
# =========================
st.subheader(" ğŸ“ êµ¬ë§¤ê°€ëŠ¥ ë©´ì (í‰) & 1í‰ êµ¬ë§¤ì— í•„ìš”í•œ ê¸°ê°„(ê°œì›”)")


# ì‚¬ìš©ìê°€ ì†Œë“ ì£¼ê¸°ë¥¼ ì„ íƒí•˜ë„ë¡ í•´ì„œ 'ê°œì›”' ì˜ë¯¸ë¥¼ í™•ì •
# âœ… ì…ë ¥ valueëŠ” "ì›”ì†Œë“(ì›)"ìœ¼ë¡œ ê³ ì • (ì¤‘ë³µ í™˜ì‚° ë°©ì§€)
st.caption("ì†Œë“ ë°ì´í„°(value)ëŠ” 'ì›”ì†Œë“(ì›)', ì•„íŒŒíŠ¸ ê°€ê²©ì€ 'ë§Œì›/í‰'ê¸°ì¤€ì…ë‹ˆë‹¤.")
df["income_monthly_won"] = df["income_value"]


# ì•„íŒŒíŠ¸ ë‹¨ìœ„ ì •ê·œí™” â†’ ì›/í‰
# âœ… ì•„íŒŒíŠ¸ í‰ë‹¹ê°€ê²©ì€ 'ë§Œì›/í‰'ìœ¼ë¡œ ê³ ì • â†’ ì›/í‰ìœ¼ë¡œ ë³€í™˜
df["apt_price_per_pyeong_won"] = df["apt_price_median"] * 10000

# êµ¬ë§¤ê°€ëŠ¥ í‰ìˆ˜(ì›”ì†Œë“ ê¸°ì¤€)
df["Purchasable_Pyeong"] = df["income_monthly_won"] / df["apt_price_per_pyeong_won"]

# âœ… 1í‰ êµ¬ë§¤ì— í•„ìš”í•œ ê°œì›” ìˆ˜(ì›”ì†Œë“ ê¸°ì¤€) â€” ì´ê²Œ ì§„ì§œ "ê°œì›”"ì„
df["Months_for_1Pyeong"] = df["apt_price_per_pyeong_won"] / df["income_monthly_won"]

st.caption(
    "ì •ì˜: 1í‰ êµ¬ë§¤ ê°œì›” ìˆ˜ = (í‰ë‹¹ê°€ê²© ë§Œì›/í‰) Ã· (ì›”ì†Œë“ ì›/ì›”). "
)

# (3-1) êµ¬ë§¤ê°€ëŠ¥ í‰ìˆ˜ ê·¸ë˜í”„: ë¸”ë™ + ë‘êº¼ìš´ ì„ 
fig3 = go.Figure()
fig3.add_trace(go.Scatter(
    x=df["Year"], y=df["Purchasable_Pyeong"],
    mode="lines+markers",
    name="êµ¬ë§¤ê°€ëŠ¥ í‰ìˆ˜(í‰)",
    line=dict(color=BLACK, width=LINE_W_THICK),
    marker=dict(size=8, color=BLACK)
))
fig3.update_layout(
    title="ì—°ë„ë³„ êµ¬ë§¤ê°€ëŠ¥ í‰ìˆ˜(ì›”ì†Œë“/í‰ë‹¹ê°€ê²©)",
    xaxis_title="ì—°ë„",
    yaxis_title="í‰",
    hovermode="x unified",
    height=460
)
st.plotly_chart(fig3, use_container_width=True)

# (3-2) 1í‰ êµ¬ë§¤ ê°œì›” ìˆ˜ ê·¸ë˜í”„: ë¸”ë™ + ë™ì¼ ë‘ê»˜
fig4 = go.Figure()
fig4.add_trace(go.Scatter(
    x=df["Year"], y=df["Months_for_1Pyeong"],
    mode="lines+markers",
    name="1í‰ êµ¬ë§¤ì— í•„ìš”í•œ ê°œì›” ìˆ˜",
    line=dict(color=BLACK, width=LINE_W_THICK),
    marker=dict(size=8, color=BLACK)
))
fig4.update_layout(
    title="ì—°ë„ë³„ 1í‰ êµ¬ë§¤ì— í•„ìš”í•œ ê¸°ê°„(ê°œì›”) = í‰ë‹¹ê°€ê²©/ì›”ì†Œë“",
    xaxis_title="ì—°ë„",
    yaxis_title="ê°œì›”",
    hovermode="x unified",
    height=460
)
st.plotly_chart(fig4, use_container_width=True)


#section 2 
# =========================================================
# ğŸ“Œ í˜ë¥´ì†Œë‚˜ ì„¹ì…˜ (ì§€ìˆ˜í™” ë¶„ì„ ì´í›„)
# =========================================================
st.markdown("---")
st.subheader("ğŸ  ë‚´ ì§‘ ë§ˆë ¨ì˜ ê¿ˆ ğŸ ")

st.markdown("**ì´Oí˜„: ë‚´ ì§‘ì€ ì–´ë””ì— ìˆì„ê¹Œ?**")

image_path = BASE_DIR / "image.png"

if image_path.exists():
    image = Image.open(image_path)
    st.image(
        image,
        caption="ì´Oí˜„ë‹˜ì˜ ë‚´ ì§‘ì„ ì°¾ì•„ì¤˜",
        use_container_width=True
    )
else:
    st.error(f"ì´ë¯¸ì§€ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {image_path.name}")
    st.info(f"'{image_path.name}' íŒŒì¼ì„ ì´ ìŠ¤í¬ë¦½íŠ¸ì™€ ê°™ì€ í´ë”ì— ë„£ì–´ì£¼ì„¸ìš”.")

st.markdown("---")

# ğŸ“‹ í”„ë¡œí•„ ì¹´ë“œ
st.subheader("ğŸ“‹ ì´Oí˜„ ê°œì¸í”„ë¡œí•„ ìƒì„¸")

col1, col2 = st.columns(2)

with col1:
    st.write("**ì´ë¦„:** ì´Oí˜„")
    st.write("**ë‚˜ì´:** 29ì„¸ (ë§Œ 27ì„¸)")
    st.write("**ì§ì—…:** í‰ë²”í•˜ê³  ì„±ì‹¤í•œ ì§ì¥ì¸")

with col2:
    st.write("**í˜„ì¬ ìƒíƒœ:** ë¯¸í˜¼ (ê²°í˜¼ ì˜ˆì •)")
    st.write("**ëª©í‘œ ì£¼íƒ:** ì„œìš¸/ìˆ˜ë„ê¶Œ 24í‰ ì•„íŒŒíŠ¸")
    st.write("**ê¸´ê¸‰ë„:** ğŸ”¥ ë§¤ìš° ë†’ìŒ, ìµœëŒ€í•œ ë¹¨ë¦¬ ê²°í˜¼í•˜ê³  ì‹¶ìŒ")  

st.markdown("---")

# ğŸ’­ ì‹œë‚˜ë¦¬ì˜¤ ì„¤ëª…
st.subheader("ğŸ’­ ë‚´ ì§‘ ë§ˆë ¨ì˜ ê¿ˆ ì‹œë‚˜ë¦¬ì˜¤ ë°°ê²½")
st.markdown("""
> **"ìˆ˜ ë§ì€ ì£¼íƒ ë°ì´í„°ê°€ ë‚˜ì—ê²ŒëŠ” ì–´ë–¤ ì˜ë¯¸ë¥¼ ê°€ì§ˆê¹Œìš”?"**

ì•ì—ì„œ ë³¸ **ì†Œë“â€“ì•„íŒŒíŠ¸ ê°€ê²© ê²©ì°¨ì˜ êµ¬ì¡°ì  ë¬¸ì œ**ë¥¼  
ì´ì œ í•œ ëª…ì˜ í˜„ì‹¤ì ì¸ ì¸ë¬¼ì—ê²Œ ì ìš©í•´ë´…ë‹ˆë‹¤.

ì´ ì‹œë®¬ë ˆì´ì…˜ì€  
**ì†Œë“ ì„±ì¥ë¥ **, **ì €ì¶• ì „ëµ**, **ê²°í˜¼(ë§ë²Œì´)** ì´  
ë‚´ ì§‘ ë§ˆë ¨ ê°€ëŠ¥ ì‹œì ì„ ì–´ë–»ê²Œ ë°”ê¾¸ëŠ”ì§€ë¥¼ ë³´ì—¬ì£¼ê¸° ìœ„í•œ ì¶œë°œì ì…ë‹ˆë‹¤.
""")

#========ì€ì •_ì‹œë®¬ë ˆì´í„°=============
# =========================================================
# ğŸ§® (ì¶”ê°€) ë‚´ ì§‘ ë§ˆë ¨ í†µí•© ì‹œë®¬ë ˆì´í„° ì„¹ì…˜
#   âœ… ìœ„ ì½”ë“œ ë‚´ìš©ì€ ê·¸ëŒ€ë¡œ ë‘ê³ , import/set_page_config/íƒ€ì´í‹€ ì¤‘ë³µ ì—†ì´
#   âœ… BASE_DIR + ì´ë¯¸ ì¡´ì¬í•˜ëŠ” ë°ì´í„°(ì†Œë“íŒŒì¼/ì•„íŒŒíŠ¸íŒŒì¼) ê¸°ì¤€ìœ¼ë¡œë§Œ ì—°ê²°
# =========================================================
st.markdown("---")
st.header("ğŸ  ë‚´ ì§‘ ë§ˆë ¨ ì‹œë®¬ë ˆì´í„°")
st.markdown("#### ğŸ“‰ ì•„íŒŒíŠ¸ ì‹¤ê±°ë˜ê°€ì™€ ì†Œë“ ë°ì´í„°ë¥¼ ì ìš©í•˜ì—¬ ì‹œë®¬ë ˆì´ì…˜")

# --------------------------------------------------------------------------
# 1) ë°ì´í„° ë¡œë“œ ë° ë³‘í•© (í”„ë¡œì íŠ¸ ë°ì´í„° êµ¬ì¡° ë°˜ì˜)
#    - ì†Œë“: 1ì¸ë‹¹_ê°œì¸ì†Œë“.csv (Year/item/hh/value)
#    - ì•„íŒŒíŠ¸: ì‹œë„_apart_YYYY_data.csv (ì‹œë„ë³„_ê±°ë˜ê¸ˆì•¡_ì¤‘ì•™ê°’ ì‚¬ìš©)
# --------------------------------------------------------------------------
@st.cache_data(show_spinner=True)
def load_and_merge_data_simulator(base_dir_str: str):
    base_dir = Path(base_dir_str)

    # âœ… ì†Œë“ íŒŒì¼(í”„ë¡œì íŠ¸)
    wage_path = base_dir / "1ì¸ë‹¹_ê°œì¸ì†Œë“.csv"
    if not wage_path.exists():
        return None, f"'{wage_path.name}' íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤."

    wage_df = pd.read_csv(wage_path)
    if "Unnamed: 0" in wage_df.columns:
        wage_df = wage_df.drop(columns=["Unnamed: 0"])

    year_col = "Year" if "Year" in wage_df.columns else ("year" if "year" in wage_df.columns else None)
    required = {"item", "hh", "value"}
    if year_col is None or not required.issubset(set(wage_df.columns)):
        return None, f"ì†Œë“ íŒŒì¼ ì»¬ëŸ¼ì´ ì˜ˆìƒê³¼ ë‹¤ë¦…ë‹ˆë‹¤. ê°ì§€ëœ ì»¬ëŸ¼: {list(wage_df.columns)}"

    # âœ… ë‚´ìš© ë³€ê²½ ì—†ì´ ìë™ ì„ íƒ(ê¸°ì¡´ê³¼ ë™ì¼): item=ì²˜ë¶„ê°€ëŠ¥ì†Œë“ ìš°ì„ , hh=1ì¸ ìš°ì„ 
    items = wage_df["item"].dropna().unique().tolist()
    hhs = wage_df["hh"].dropna().unique().tolist()
    item_choice = "ì²˜ë¶„ê°€ëŠ¥ì†Œë“" if "ì²˜ë¶„ê°€ëŠ¥ì†Œë“" in items else (items[0] if items else None)
    hh_choice = "1ì¸" if "1ì¸" in hhs else (hhs[0] if hhs else None)

    if item_choice is None or hh_choice is None:
        return None, "ì†Œë“ íŒŒì¼ì—ì„œ item/hh ê°’ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

    wage_selected = wage_df.loc[
        (wage_df["item"] == item_choice) & (wage_df["hh"] == hh_choice),
        [year_col, "value"]
    ].copy()

    wage_selected[year_col] = pd.to_numeric(wage_selected[year_col], errors="coerce")
    wage_selected["value"] = pd.to_numeric(wage_selected["value"], errors="coerce")
    wage_selected = wage_selected.dropna()

    # âœ… valueëŠ” 'ì›”ì†Œë“(ì›)' â†’ ì—°ì†Œë“ìœ¼ë¡œ í™˜ì‚°í•´ì„œ ì—°ë´‰ ê¸°ë°˜ ì €ì¶•ì— ì‚¬ìš©
    wage_selected = wage_selected.rename(columns={year_col: "year", "value": "monthly_wage_won"})
    wage_selected["year"] = wage_selected["year"].astype(int)

    # ì—°ë„ë³„ í‰ê·  ì›”ì†Œë“(ì›)
    wage_selected = wage_selected.groupby("year", as_index=False)["monthly_wage_won"].mean()

    # ì—°ì†Œë“(ì›) = ì›”ì†Œë“ Ã— 12
    wage_selected["annual_wage_won"] = wage_selected["monthly_wage_won"] * 12

    # ì—°ì†Œë“(ë§Œì›)
    wage_selected["annual_wage_manwon"] = wage_selected["annual_wage_won"] / 10000.0

    # âœ… ì•„íŒŒíŠ¸ íŒŒì¼(í”„ë¡œì íŠ¸) - BASE_DIR ê¸°ì¤€
    files_in_dir_local = sorted([p.name for p in base_dir.iterdir()])
    apt_pat_local = re.compile(r"^ì‹œë„_apart_(\d{4})_data\.csv$")
    apart_paths = sorted([base_dir / fn for fn in files_in_dir_local if apt_pat_local.match(nfc(fn))])

    if not apart_paths:
        return None, "ì•„íŒŒíŠ¸ ë°ì´í„° íŒŒì¼(ì‹œë„_apart_YYYY_data.csv)ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

    apart_data_list = []
    for path in apart_paths:
        m = re.search(r"ì‹œë„_apart_(\d{4})_data\.csv$", nfc(path.name))
        if not m:
            continue
        year = int(m.group(1))

        temp_df = pd.read_csv(path)

        # âœ… ì‹œë®¬ë ˆì´í„°ëŠ” ê±°ë˜ê¸ˆì•¡(ë§Œì›)ì„ ì¨ì•¼ ê¸°ì¡´ ê³„ì‚°/í‘œí˜„ì´ ê·¸ëŒ€ë¡œ ìœ ì§€ë¨
        if "ì‹œë„ë³„_ê±°ë˜ê¸ˆì•¡_ì¤‘ì•™ê°’" in temp_df.columns and "ì‹œë„" in temp_df.columns:
            sub_df = temp_df[["ì‹œë„", "ì‹œë„ë³„_ê±°ë˜ê¸ˆì•¡_ì¤‘ì•™ê°’"]].copy()
            sub_df["year"] = year
            apart_data_list.append(sub_df)

    if not apart_data_list:
        return None, "ì•„íŒŒíŠ¸ íŒŒì¼ì€ ìˆì§€ë§Œ 'ì‹œë„ë³„_ê±°ë˜ê¸ˆì•¡_ì¤‘ì•™ê°’' ì»¬ëŸ¼ì„ ê°€ì§„ ë°ì´í„°ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."

    apart_all = pd.concat(apart_data_list, ignore_index=True)

    # ë³‘í•©(ê¸°ì¡´ê³¼ ë™ì¼)
    merged_df = pd.merge(apart_all, wage_selected[["year", "annual_wage_manwon"]], on="year", how="left")
    return merged_df, None


raw_data_sim, error_message_sim = load_and_merge_data_simulator(str(BASE_DIR))


# --------------------------------------------------------------------------
# 2) UI (ì‹œë®¬ë ˆì´ì…˜ ì„¤ì • + ê¸°ì¤€ì—°ë„ í†µí•©)
# --------------------------------------------------------------------------
with st.container():
    st.subheader("âš™ï¸ ì‹œë®¬ë ˆì´ì…˜ ì„¤ì •")

    col0, col1, col2, col3 = st.columns(4)

    with col0:
        available_years = sorted(raw_data_sim["year"].unique())
        default_idx = len(available_years) - 1

        selected_year = st.selectbox(
            "ğŸ—“ï¸ ë°ì´í„° ê¸°ì¤€ ì—°ë„",
            available_years,
            index=default_idx,
            help="ì´ ì—°ë„ì˜ ì†Œë“Â·ì•„íŒŒíŠ¸ ë°ì´í„°ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì‹œë®¬ë ˆì´ì…˜í•©ë‹ˆë‹¤.",
            key="sim_selected_year"
        )

    with col1:
        savings_rate = st.slider(
            "ğŸ’° ì €ì¶•ë¥  (%)",
            min_value=10, max_value=100, value=50, step=5,
            key="sim_savings_rate"
        )

    with col2:
        salary_growth_rate = st.slider(
            "ğŸ“ˆ ë§¤ë…„ ì—°ë´‰ ìƒìŠ¹ë¥  (%)",
            min_value=0.0, max_value=10.0, value=3.0, step=0.5,
            key="sim_salary_growth_rate"
        )

    with col3:
    # âœ… ë°°ìš°ì ê¸°ë³¸ê°’ = ë³¸ì¸ ì—°ë´‰ê³¼ ë™ì¼
        subset_for_default = raw_data_sim[raw_data_sim["year"] == selected_year]
        my_income = subset_for_default["annual_wage_manwon"].dropna().mean()
        default_spouse = int(my_income) if pd.notna(my_income) else 4000

        spouse_income = st.slider(
             "ğŸ‘« ë°°ìš°ì ì—°ë´‰ (ë§Œì›)",
            min_value=0,
            max_value=10000,
            value=default_spouse,
            step=100,
            help="ê¸°ë³¸ê°’ì€ ë³¸ì¸ ì—°ë´‰ê³¼ ë™ì¼í•˜ê²Œ ì„¤ì •ë©ë‹ˆë‹¤.",
            key="sim_spouse_income"
    )

st.info(f"âœ… {selected_year}ë…„ ë°ì´í„°ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì‹œë®¬ë ˆì´ì…˜í•©ë‹ˆë‹¤.")


    # --------------------------------------------------------------------------
    # 4) ê³„ì‚° ë¡œì§ (ê¸°ì¡´ ê·¸ëŒ€ë¡œ)
    # --------------------------------------------------------------------------
def calculate_years(target_price, initial_income, save_rate, growth_rate):
    saved_amount = 0
    years = 0
    current_income = initial_income

    if initial_income <= 0 or pd.isna(target_price):
        return 999

    while saved_amount < target_price and years < 100:
        annual_saving = current_income * (save_rate / 100)
        saved_amount += annual_saving
        current_income *= (1 + growth_rate / 100)
        years += 1

    return years

if raw_data_sim is None:
    st.error("ğŸš¨ ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    st.warning(f"ì˜¤ë¥˜ ë‚´ìš©: {error_message_sim}")
    st.markdown("""
**í•´ê²° ë°©ë²•:**
1. ë‹¤ìŒ íŒŒì¼ë“¤ì´ ì´ íŒŒì´ì¬ íŒŒì¼ê³¼ ê°™ì€ í´ë”ì— ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.
   - `1ì¸ë‹¹_ê°œì¸ì†Œë“.csv`
   - `ì‹œë„_apart_2010_data.csv`
   - `ì‹œë„_apart_2015_data.csv`
   - `ì‹œë„_apart_2020_data.csv`
   - `ì‹œë„_apart_2025_data.csv`
   - (ì•„íŒŒíŠ¸ íŒŒì¼ì—ëŠ” `ì‹œë„ë³„_ê±°ë˜ê¸ˆì•¡_ì¤‘ì•™ê°’` ì»¬ëŸ¼ì´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.)
""")
    st.stop()

    # --------------------------------------------------------------------------
# 5) ê²°ê³¼ íƒ­ (ê¸°ì¤€ì—°ë„ ì„¤ì • íƒ­ ì œê±°: ê²°ê³¼ë§Œ 3ê°œ)
#   - tab1: ì €ì¶•ì˜ í˜(ê¸°ë³¸)
#   - tab2: ì„±ì¥ì˜ í˜(ì—°ë´‰ìƒìŠ¹)
#   - tab3: í•¨ê»˜ì˜ í˜(ë§ë²Œì´)
# --------------------------------------------------------------------------
tab1, tab2, tab3 = st.tabs([
    "ğŸ“Š ì €ì¶•ì˜ í˜ (ê¸°ë³¸)",
    "ğŸ“ˆ ì„±ì¥ì˜ í˜ (ì—°ë´‰ìƒìŠ¹)",
    "ğŸ‘« í•¨ê»˜ì˜ í˜ (ë§ë²Œì´)"
])

# âœ… ìœ„ìª½ ì‹œë®¬ë ˆì´ì…˜ ì„¤ì •ì—ì„œ selected_yearë¥¼ ì´ë¯¸ ì„ íƒí–ˆë‹¤ê³  ê°€ì •
subset = raw_data_sim[raw_data_sim["year"] == selected_year].copy()

df_sim = pd.DataFrame({
    "ì§€ì—­": subset["ì‹œë„"],
    "ë³¸ì¸ì—°ë´‰(ì¤‘ìœ„)": subset["annual_wage_manwon"],        # ë§Œì›
    "ì•„íŒŒíŠ¸ì¤‘ìœ„ê°€ê²©": subset["ì‹œë„ë³„_ê±°ë˜ê¸ˆì•¡_ì¤‘ì•™ê°’"],    # ë§Œì›
}).dropna(subset=["ë³¸ì¸ì—°ë´‰(ì¤‘ìœ„)", "ì•„íŒŒíŠ¸ì¤‘ìœ„ê°€ê²©"])

df_sim = df_sim.sort_values("ì•„íŒŒíŠ¸ì¤‘ìœ„ê°€ê²©", ascending=False).reset_index(drop=True)

# =========================
# TAB 1) ì €ì¶•ì˜ í˜ (ê¸°ë³¸)
# =========================


with tab1:
    df_basic = df_sim.copy()

    df_basic["ë³¸ì¸ì—°ë´‰(ì¤‘ìœ„)"] = pd.to_numeric(df_basic["ë³¸ì¸ì—°ë´‰(ì¤‘ìœ„)"], errors="coerce")
    df_basic["ì•„íŒŒíŠ¸ì¤‘ìœ„ê°€ê²©"] = pd.to_numeric(df_basic["ì•„íŒŒíŠ¸ì¤‘ìœ„ê°€ê²©"], errors="coerce")
    df_basic = df_basic.dropna(subset=["ë³¸ì¸ì—°ë´‰(ì¤‘ìœ„)", "ì•„íŒŒíŠ¸ì¤‘ìœ„ê°€ê²©"])

    if df_basic.empty:
        st.error("ê·¸ë˜í”„ë¥¼ ê·¸ë¦´ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. (ì—°ë´‰/ì•„íŒŒíŠ¸ê°€ê²© ê²°ì¸¡)")
        st.stop()

    df_basic["ì†Œìš”ì‹œê°„"] = df_basic.apply(
        lambda x: calculate_years(x["ì•„íŒŒíŠ¸ì¤‘ìœ„ê°€ê²©"], x["ë³¸ì¸ì—°ë´‰(ì¤‘ìœ„)"], savings_rate, 0),
        axis=1
    )

    df_basic["ì†Œìš”ì‹œê°„"] = pd.to_numeric(df_basic["ì†Œìš”ì‹œê°„"], errors="coerce")
    df_basic = df_basic.dropna(subset=["ì†Œìš”ì‹œê°„"])

    df_basic["ì˜ˆìƒêµ¬ë§¤ì—°ë„"] = selected_year + df_basic["ì†Œìš”ì‹œê°„"]  # base_year ìˆìœ¼ë©´ base_yearë¡œ ë°”ê¾¸ëŠ” ê²Œ ë” ì¢‹ìŒ
    df_basic = df_basic.sort_values("ì†Œìš”ì‹œê°„", ascending=False)

    fig1 = px.bar(
        df_basic,
        x="ì§€ì—­",
        y="ì†Œìš”ì‹œê°„",
        color="ì†Œìš”ì‹œê°„",
        text="ì†Œìš”ì‹œê°„",
        title="ì§€ì—­ë³„ ë‚´ ì§‘ ë§ˆë ¨ ì†Œìš” ì‹œê°„ (ë…„)",
        hover_data={"ì˜ˆìƒêµ¬ë§¤ì—°ë„": True},
        color_continuous_scale="Blues"
    )
    fig1.update_traces(texttemplate="%{text}ë…„", textposition="outside", cliponaxis=False)

    st.plotly_chart(fig1, use_container_width=True)


# =========================
# TAB 2) ì„±ì¥ì˜ í˜ (ì—°ë´‰ìƒìŠ¹)
# =========================
with tab2:
    df_growth = df_sim.copy()
    df_growth["ê³ ì •ì—°ë´‰"] = df_growth.apply(
        lambda x: calculate_years(x["ì•„íŒŒíŠ¸ì¤‘ìœ„ê°€ê²©"], x["ë³¸ì¸ì—°ë´‰(ì¤‘ìœ„)"], savings_rate, 0),
        axis=1
    )
    df_growth["ìƒìŠ¹ì—°ë´‰"] = df_growth.apply(
        lambda x: calculate_years(x["ì•„íŒŒíŠ¸ì¤‘ìœ„ê°€ê²©"], x["ë³¸ì¸ì—°ë´‰(ì¤‘ìœ„)"], savings_rate, salary_growth_rate),
        axis=1
    )

    df_growth["ê³ ì •_ì˜ˆìƒêµ¬ë§¤ì—°ë„"] = selected_year + df_growth["ê³ ì •ì—°ë´‰"]
    df_growth["ìƒìŠ¹_ì˜ˆìƒêµ¬ë§¤ì—°ë„"] = selected_year + df_growth["ìƒìŠ¹ì—°ë´‰"]

    df_melted = df_growth.melt(
        id_vars="ì§€ì—­",
        value_vars=["ê³ ì •ì—°ë´‰", "ìƒìŠ¹ì—°ë´‰"],
        var_name="êµ¬ë¶„",
        value_name="ì†Œìš”ì‹œê°„"
    )
    df_melted["êµ¬ë¶„"] = df_melted["êµ¬ë¶„"].map({
        "ê³ ì •ì—°ë´‰": "âŒ ì—°ë´‰ ë™ê²°",
        "ìƒìŠ¹ì—°ë´‰": f"â­• ë§¤ë…„ {salary_growth_rate}% ìƒìŠ¹"
    })

    st.subheader(f"ğŸ“ˆ ì—°ë´‰ ìƒìŠ¹ë¥  {salary_growth_rate}% ì ìš© íš¨ê³¼ (ê¸°ì¤€={selected_year}ë…„)")

    fig2 = px.bar(
        df_melted, x="ì§€ì—­", y="ì†Œìš”ì‹œê°„",
        color="êµ¬ë¶„", barmode="group", text="ì†Œìš”ì‹œê°„",
        title="ì—°ë´‰ ìƒìŠ¹ ìœ ë¬´ ë¹„êµ"
    )
    fig2.update_traces(texttemplate="%{text}ë…„", textposition="outside")
    st.plotly_chart(fig2, use_container_width=True)

# =========================
# TAB 3) í•¨ê»˜ì˜ í˜ (ë§ë²Œì´)
# =========================
with tab3:
    df_mate = df_sim.copy()
    df_mate["ì™¸ë²Œì´"] = df_mate.apply(
        lambda x: calculate_years(x["ì•„íŒŒíŠ¸ì¤‘ìœ„ê°€ê²©"], x["ë³¸ì¸ì—°ë´‰(ì¤‘ìœ„)"], savings_rate, salary_growth_rate),
        axis=1
    )
    df_mate["ë§ë²Œì´"] = df_mate.apply(
        lambda x: calculate_years(x["ì•„íŒŒíŠ¸ì¤‘ìœ„ê°€ê²©"], x["ë³¸ì¸ì—°ë´‰(ì¤‘ìœ„)"] + spouse_income, savings_rate, salary_growth_rate),
        axis=1
    )

    df_mate["ì™¸ë²Œì´_ì˜ˆìƒêµ¬ë§¤ì—°ë„"] = selected_year + df_mate["ì™¸ë²Œì´"]
    df_mate["ë§ë²Œì´_ì˜ˆìƒêµ¬ë§¤ì—°ë„"] = selected_year + df_mate["ë§ë²Œì´"]

    df_melted_mate = df_mate.melt(
        id_vars="ì§€ì—­",
        value_vars=["ì™¸ë²Œì´", "ë§ë²Œì´"],
        var_name="êµ¬ë¶„",
        value_name="ì†Œìš”ì‹œê°„"
    )
    df_melted_mate["êµ¬ë¶„"] = df_melted_mate["êµ¬ë¶„"].map({"ì™¸ë²Œì´": "ğŸ§ ì™¸ë²Œì´", "ë§ë²Œì´": "ğŸ‘« ë§ë²Œì´"})

    st.subheader(f"ğŸ‘« ë°°ìš°ì ì—°ë´‰ {spouse_income:,}ë§Œì› í•©ì‚° íš¨ê³¼ (ê¸°ì¤€={selected_year}ë…„)")

    fig3 = px.bar(
        df_melted_mate, x="ì§€ì—­", y="ì†Œìš”ì‹œê°„",
        color="êµ¬ë¶„", barmode="group", text="ì†Œìš”ì‹œê°„",
        title="ì™¸ë²Œì´ vs ë§ë²Œì´ ë¹„êµ"
    )
    fig3.update_traces(texttemplate="%{text}ë…„", textposition="outside", cliponaxis=False)
    st.plotly_chart(fig3, use_container_width=True)

#==========ì‹œë®¬ë ˆì´í„° ë=================

st.header("ğŸƒâ€â™‚ï¸ ë‹¬ë ¤ë„ ì¡ì„ ìˆ˜ ì—†ëŠ” ì§‘ â€” ì‹œê°„ ì‹œë®¬ë ˆì´ì…˜")

region = st.radio("ì§€ì—­ ì„ íƒ", ["ì„œìš¸", "ê²½ê¸°", "ì§€ë°©"], horizontal=True)

INCOME_PATH = BASE_DIR / "1ì¸ë‹¹_ê°œì¸ì†Œë“.csv"

APT_COL = "ì‹œë„ë³„_ê±°ë˜ê¸ˆì•¡_ì¤‘ì•™ê°’"
base_years = [2010, 2015, 2020, 2025]

scenarios = [
    "1ì¸Â·ê°€ì²˜ë¶„ì†Œë“",
    "ìº¥ê±°ë£¨Â·ê·¼ë¡œì†Œë“",
    "ë§ë²Œì´Â·ì†Œë“2ë°°",
    "+ì£¼ì‹Â·ì†Œë“3ë°°",   # âœ… 3.5ë°° â†’ 3ë°°ë¡œ í‘œê¸° ë³€ê²½
]
lane_y = {scenarios[0]: 3, scenarios[1]: 2, scenarios[2]: 1, scenarios[3]: 0}

@st.cache_data(show_spinner=False)
def load_income_raw() -> pd.DataFrame:
    df = pd.read_csv(INCOME_PATH)
    if "Unnamed: 0" in df.columns:
        df = df.drop(columns=["Unnamed: 0"])

    if "Year" in df.columns and "year" not in df.columns:
        df = df.rename(columns={"Year": "year"})

    df["year"] = pd.to_numeric(df["year"], errors="coerce")
    df["value"] = pd.to_numeric(df["value"], errors="coerce")
    df = df.dropna(subset=["year", "item", "hh", "value"])
    df["year"] = df["year"].astype(int)
    return df

@st.cache_data(show_spinner=False)
def get_monthly_income_won(
    year: int,
    item_name: str = "ì²˜ë¶„ê°€ëŠ¥ì†Œë“",
    hh_name: str = "1ì¸",
) -> float:
    df = load_income_raw()
    sub = df[(df["year"] == year) & (df["hh"] == hh_name)]
    hit = sub[sub["item"] == item_name]
    if hit.empty:
        hit = sub[sub["item"].astype(str).str.contains(item_name, na=False)]
    if hit.empty:
        raise ValueError(f"{year}ë…„ ì†Œë“ ë°ì´í„°ì—ì„œ item={item_name}, hh={hh_name}ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
    return float(hit["value"].mean())

@st.cache_data(show_spinner=False)
def get_house_price_manwon(year: int, region_label: str) -> float:
    path = BASE_DIR / f"ì‹œë„_apart_{year}_data.csv"
    apt = pd.read_csv(path)

    if APT_COL not in apt.columns:
        raise ValueError(f"{path.name} ì— '{APT_COL}' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤. í˜„ì¬ ì»¬ëŸ¼: {list(apt.columns)}")

    apt[APT_COL] = pd.to_numeric(apt[APT_COL], errors="coerce")
    apt = apt.dropna(subset=[APT_COL])

    if region_label == "ì„œìš¸":
        row = apt[apt["ì‹œë„"].astype(str).str.contains("ì„œìš¸")]
        if row.empty:
            raise ValueError(f"{path.name}: 'ì„œìš¸' ì‹œë„ í–‰ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        return float(row[APT_COL].iloc[0])

    if region_label == "ê²½ê¸°":
        row = apt[apt["ì‹œë„"].astype(str).str.contains("ê²½ê¸°")]
        if row.empty:
            raise ValueError(f"{path.name}: 'ê²½ê¸°' ì‹œë„ í–‰ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        return float(row[APT_COL].iloc[0])

    other = apt[~apt["ì‹œë„"].astype(str).str.contains("ì„œìš¸|ê²½ê¸°")]
    if other.empty:
        raise ValueError(f"{path.name}: ì§€ë°©(ì„œìš¸/ê²½ê¸° ì œì™¸) ë°ì´í„°ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
    return float(other[APT_COL].median())

@st.cache_data(show_spinner=False)
def build_data_real() -> dict:
    SAVE_RATE = 0.50
    KANGAROO_SAVE_RATE = 1.00
    COUPLE_MULT = 2.0

    # âœ… ì£¼ì‹ ê°€ì • ì„¸ë¶„í™”: "ì´ì†Œë“ = ê¸°ì¡´ì†Œë“ Ã— 3"
    STOCK_TOTAL_INCOME_MULT = 3.0

    out = {reg: {s: {} for s in scenarios} for reg in ["ì„œìš¸", "ê²½ê¸°", "ì§€ë°©"]}

    for reg in ["ì„œìš¸", "ê²½ê¸°", "ì§€ë°©"]:
        for y in base_years:
            house_price_manwon = get_house_price_manwon(y, reg)

            monthly_income_won = get_monthly_income_won(y, item_name="ì²˜ë¶„ê°€ëŠ¥ì†Œë“", hh_name="1ì¸")
            annual_income_manwon = (monthly_income_won * 12.0) / 10000.0

            save_1 = annual_income_manwon * SAVE_RATE
            save_2 = annual_income_manwon * KANGAROO_SAVE_RATE
            save_3 = (annual_income_manwon * COUPLE_MULT) * SAVE_RATE

            # âœ… ì´ì†Œë“ì„ 3ë°°ë¡œ ë§Œë“  ë’¤ ì €ì¶•ë¥ (50%) ì ìš©
            save_4 = (annual_income_manwon * STOCK_TOTAL_INCOME_MULT) * SAVE_RATE

            scenario_save = {
                scenarios[0]: save_1,
                scenarios[1]: save_2,
                scenarios[2]: save_3,
                scenarios[3]: save_4,
            }

            for s in scenarios:
                denom = max(float(scenario_save[s]), 1e-9)
                years_needed = int(np.ceil(float(house_price_manwon) / denom))
                out[reg][s][y] = max(1, years_needed)

    return out

data = build_data_real()

# âœ… ì‹œë®¬ë ˆì´ì…˜ í”„ë ˆì„(ì¤‘ê°„ì—°ë„)ì—ì„œ ì‚¬ìš©í•  "í•´ë‹¹ ì‹œì  ê¸°ì¤€ì—°ë„" ë§¤í•‘
def to_base_year(curr_year: int) -> int:
    if curr_year <= 2010:
        return 2010
    if curr_year <= 2015:
        return 2015
    if curr_year <= 2020:
        return 2020
    return 2025

earliest_purchase_year = {
    s: min(by + data[region][s][by] for by in base_years)
    for s in scenarios
}

PERSON_EMOJI = {
    scenarios[0]: "ğŸƒâ€â™‚ï¸",
    scenarios[1]: "ğŸ¦˜",
    scenarios[2]: "ğŸ’‘",
    scenarios[3]: "ğŸ“ˆ",
}
HOUSE_EMOJI = "ğŸ "

LANE_DESC = {
    scenarios[0]: "1. ìƒí™œë¹„ë¥¼ ì œì™¸í•œ ê¸ˆì•¡ìœ¼ë¡œ ëˆì„ ëª¨ì€ë‹¤ë©´?, ì €ì¶•ë¥  50%",
    scenarios[1]: "2. ìº¥ê±°ë£¨ì²˜ëŸ¼ ë¶€ëª¨ë‹˜ê»˜ ì˜ì¡´í•˜ê³  ì›”ê¸‰ ì „ë¶€ëŠ” ì§‘ ì‚¬ëŠ” ê³³ì— ë„£ëŠ”ë‹¤ë©´?",
    scenarios[2]: "3. ë§ë²Œì´ë¡œ ë°°ìš°ìì™€ í•¨ê»˜ ëˆì„ ëª¨ì€ë‹¤ë©´?",
    scenarios[3]: "4. ì£¼ì‹ìœ¼ë¡œ â€˜ì´ì†Œë“=ë‚´ì†Œë“Ã—3â€™ì´ ëœë‹¤ë©´?",
}

steps_between = 14
pause_frames = 3
jump_pause_frames = 1
shake_offsets = [0.35, -0.2, 0.0]

X_MIN, X_MAX = 2010, 2075

Q_X = 0.92
Q_DY = +0.5

def box_text(year: int, years_needed: int) -> str:
    highlight = "#FFD54A"
    return (
        f"<span style='font-size:14px;'>{year}ë…„ ê¸°ì¤€</span>"
        f"<br>"
        f"<span style='font-size:20px; font-weight:800; color:{highlight};'>{years_needed}ë…„</span>"
        f"<span style='font-size:14px;'> ê±¸ë¦¼</span>"
    )

def scenario_boxes(label_year: int):
    anns = []
    for s in scenarios:
        y = lane_y[s]
        yrs = data[region][s][label_year]
        anns.append(
            dict(
                x=0.02, y=y, xref="paper", yref="y",
                text=box_text(label_year, yrs),
                showarrow=False,
                xanchor="left",
                yanchor="middle",
                align="left",
                font=dict(size=14, color="rgba(255,255,255,0.95)"),
                bgcolor="rgba(20,20,24,0.90)",
                bordercolor="rgba(255,255,255,0.18)",
                borderwidth=1,
                borderpad=10,
            )
        )
    return anns

def question_above_emoji():
    anns = []
    for s in scenarios:
        y = lane_y[s]
        anns.append(
            dict(
                x=Q_X, y=y + Q_DY,
                xref="paper", yref="y",        # âœ… xì¶•ì´ ì•„ë‹ˆë¼ í™”ë©´ ê¸°ì¤€!
                text=f"<span style='font-size:13px; opacity:0.92;'><b>{LANE_DESC[s]}</b></span>",
                showarrow=False,
                xanchor="right",               # âœ… ì˜¤ë¥¸ìª½ ê¸°ì¤€ìœ¼ë¡œ ì¡ê³ 
                yanchor="middle",
                align="right",                 # âœ… ê¸€ì´ ì™¼ìª½ìœ¼ë¡œ ë»—ê²Œ í•´ì„œ ì•ˆ ì˜ë¦¬ê²Œ
                font=dict(size=30, color="rgba(255,255,255,0.90)"),
                bgcolor="rgba(0,0,0,0)",
)

        )
    return anns

def house_year_labels(label_year: int, house_x_map: dict):
    anns = []
    for s in scenarios:
        y = lane_y[s]
        yrs = data[region][s][label_year]
        hx = house_x_map[s]
        anns.append(
            dict(
                x=hx, y=y - 0.25, xref="x", yref="y",
                text=f"<b>{yrs}ë…„</b>",
                showarrow=False,
                xanchor="center", yanchor="middle",
                font=dict(size=14, color="rgba(0,0,0,0.92)"),
                bgcolor="rgba(255,255,255,0.92)",
                bordercolor="rgba(0,0,0,0.25)",
                borderwidth=1,
                borderpad=5,
            )
        )
    return anns

# âœ… ì‹œë‚˜ë¦¬ì˜¤ë³„ ìµœì´ˆ ì§‘ ì¥ë§Œ ì—°ë„(ê³ ì •ê°’) ì‚¬ìš©
PURCHASE_YEAR = {s: min(by + data[region][s][by] for by in base_years) for s in scenarios}

def buy_labels(person_x: float):
    anns = []
    for s in scenarios:
        y = lane_y[s]
        done_year = float(PURCHASE_YEAR[s])
        if person_x >= done_year:  # âœ… ìµœì´ˆ ì¥ë§Œ ì—°ë„ì— ë„ë‹¬í•˜ë©´ ëœ¸
            anns.append(
                dict(
                    x=float(person_x), y=y + 0.20,
                    xref="x", yref="y",
                    text="ğŸ  <b>ì§‘ ì¥ë§Œ!</b>",
                    showarrow=False,
                    xanchor="center", yanchor="middle",
                    font=dict(size=14, color="rgba(255,255,255,0.95)"),
                    bgcolor="rgba(0,0,0,0.82)",
                    bordercolor="rgba(255,255,255,0.22)",
                    borderwidth=1,
                    borderpad=7,
                )
            )
    return anns

def frame_annotations(person_x, house_x_map, label_year):
    return (
        scenario_boxes(label_year)
        + question_above_emoji()
        + house_year_labels(label_year, house_x_map)
        + buy_labels(person_x)
    )

init_year = 2010
init_person_x = 2010.0
init_house_map = {s: init_year + data[region][s][init_year] for s in scenarios}

traces = []

for s in scenarios:
    y = lane_y[s]
    traces.append(
        go.Scatter(
            x=[X_MIN, init_person_x], y=[y, y],
            mode="lines",
            line=dict(width=7, color="rgba(255,255,255,0.28)"),
            showlegend=False,
            hoverinfo="skip",
        )
    )

for s in scenarios:
    y = lane_y[s]
    traces.append(
        go.Scatter(
            x=[init_person_x], y=[y],
            mode="text",
            text=[PERSON_EMOJI[s]],
            textfont=dict(size=34),
            showlegend=False,
            hoverinfo="skip",
        )
    )

for s in scenarios:
    y = lane_y[s]
    traces.append(
        go.Scatter(
            x=[init_house_map[s]], y=[y],
            mode="text",
            text=[HOUSE_EMOJI],
            textfont=dict(size=34),
            showlegend=False,
            hoverinfo="skip",
        )
    )

frames = []

def add_frame(person_x: float, house_x_map: dict, label_year: int):
    updates = []
    for _ in scenarios:
        updates.append(dict(x=[X_MIN, person_x]))
    for _ in scenarios:
        updates.append(dict(x=[person_x]))
    for s in scenarios:
        updates.append(dict(x=[house_x_map[s]]))

    frames.append(
        go.Frame(
            data=updates,
            traces=list(range(len(traces))),
            layout=go.Layout(annotations=frame_annotations(person_x, house_x_map, label_year)),
        )
    )

for i in range(len(base_years) - 1):
    start_year = base_years[i]
    end_year = base_years[i + 1]

    house_prev = {s: start_year + data[region][s][start_year] for s in scenarios}
    house_new  = {s: end_year   + data[region][s][end_year]   for s in scenarios}

    for t in np.linspace(0, 1, steps_between):
        person_x = start_year + (end_year - start_year) * t
        add_frame(person_x, house_prev, label_year=start_year)

    for _ in range(jump_pause_frames):
        add_frame(end_year, house_new, label_year=end_year)

    for off in shake_offsets:
        house_shake = {s: house_new[s] + off for s in scenarios}
        add_frame(end_year, house_shake, label_year=end_year)

    for _ in range(pause_frames):
        add_frame(end_year, house_new, label_year=end_year)

final_year = base_years[-1]
final_house = {s: final_year + data[region][s][final_year] for s in scenarios}
for off in shake_offsets:
    add_frame(final_year, {s: final_house[s] + off for s in scenarios}, label_year=final_year)
for _ in range(pause_frames):
    add_frame(final_year, final_house, label_year=final_year)

fig = go.Figure(data=traces, frames=frames)

fig.update_layout(
    height=820,
    paper_bgcolor="#0b0b0f",
    plot_bgcolor="#0b0b0f",
    font=dict(color="rgba(255,255,255,0.92)"),
    annotations=frame_annotations(init_person_x, init_house_map, init_year),

    xaxis=dict(
        autorange=False,          # âœ… ìë™ OFF (ì¶•ì„ ê³ ì •)
        range=[X_MAX, X_MIN],     # âœ… 2075 â†’ 2010 (ë’¤ì§‘íŒ ì¶•)
        tickmode="linear",
        tick0=X_MAX,              # âœ… 2075ë¶€í„° ëˆˆê¸ˆ ìƒì„±
        dtick=1,
        title=dict(text="ì‹œê°„ íë¦„ (ì—°ë„)", font=dict(size=16, color="rgba(255,255,255,0.88)")),
        showgrid=True,
        gridcolor="rgba(255,255,255,0.07)",
        zeroline=False,
        linecolor="rgba(255,255,255,0.15)",
        tickfont=dict(color="rgba(255,255,255,0.78)"),
        ),


    yaxis=dict(
        range=[-1.10, 4.10],
        showgrid=False,
        zeroline=False,
        showticklabels=False,
        ticks="",
    ),

    updatemenus=[
        dict(
            type="buttons",
            showactive=False,
            bgcolor="rgba(20,20,24,0.92)",
            bordercolor="rgba(255,255,255,0.18)",
            borderwidth=1,
            buttons=[
                dict(
                    label="â–¶ ì¬ìƒ",
                    method="animate",
                    args=[None, {
                        "frame": {"duration": 80, "redraw": True},
                        "transition": {"duration": 0},
                        "fromcurrent": True
                    }]
                ),
                dict(
                    label="â¸ ì •ì§€",
                    method="animate",
                    args=[[None], {"frame": {"duration": 0, "redraw": False}, "mode": "immediate"}]
                ),
            ],
            x=0.0, y=1.15, xanchor="left", yanchor="top"
        )
    ],

    margin=dict(l=35, r=30, t=115, b=55),
)

st.plotly_chart(fig, use_container_width=True)

st.caption(
    f"ì§€ì—­: {region} | value=ì›”ì†Œë“(ì›) | ì €ì¶•ë¥ (1)=50% | ìº¥ê±°ë£¨(2)=100% | ë§ë²Œì´(3)=2ë°° | "
    f"ì£¼ì‹(4)=ì´ì†Œë“ 3ë°° | ìµœì´ˆ ì§‘ ì¥ë§Œ ì—°ë„: { {s: int(earliest_purchase_year[s]) for s in scenarios} }"
)


# =========================================================
# ğŸ ì—”ë”© ì„¹ì…˜
# =========================================================
st.markdown("---")
st.header("ğŸ ê²°ë¡ : ë°ì´í„°ê°€ ë§í•´ì£¼ëŠ” ê²ƒ")

ending_image_path = BASE_DIR / "image2.png"

if ending_image_path.exists():
    st.image(
        Image.open(ending_image_path),
        caption="ì‘ì€ ì„ íƒì˜ ì°¨ì´ê°€ ë§Œë“œëŠ” ë¯¸ë˜",
        use_container_width=True
    )

st.markdown("### ğŸ“¢ ìš°ë¦¬ê°€ ë§ˆì£¼í•œ í˜„ì‹¤, ê·¸ë¦¬ê³  ëŒíŒŒêµ¬")

st.info("""
**â€œì§‘ ì‚¬ê¸° í˜ë“  ì„¸ìƒì…ë‹ˆë‹¤.â€**  
í•˜ì§€ë§Œ ë°ì´í„°ëŠ” **ì ˆë§ì´ ì•„ë‹ˆë¼ ì „ëµì˜ ê·¼ê±°**ì…ë‹ˆë‹¤.

- ì†Œë“ë§Œìœ¼ë¡œëŠ” ì–´ë µë‹¤ â†’ **ì„±ì¥ì˜ ì†ë„**ê°€ ì¤‘ìš”  
- ì €ì¶•ë§Œìœ¼ë¡œëŠ” ë¶€ì¡±í•˜ë‹¤ â†’ **ìë³¸ì˜ ì‹œê°„**ì´ í•„ìš”  
- í˜¼ìì„œëŠ” ê¸¸ë‹¤ â†’ **í•¨ê»˜ë¼ë©´ í˜„ì‹¤ì´ ëœë‹¤**
""")

col_end1, col_end2, col_end3 = st.columns(3)

with col_end1:
    st.markdown("#### ğŸš€ Self-Growth")
    st.caption("ì†Œë“ ì„±ì¥")
    st.write("ì—°ë´‰ ìƒìŠ¹ë¥  2~3%ì˜ ì°¨ì´ê°€ 10ë…„ í›„ ìì‚° ê²©ì°¨ë¥¼ ë§Œë“­ë‹ˆë‹¤.")

with col_end2:
    st.markdown("#### ğŸ’° Investment")
    st.caption("ìë³¸ í™œìš©")
    st.write("ë‹¨ìˆœ ì €ì¶•ì„ ë„˜ì–´ ìì‚°ì´ ì¼í•˜ê²Œ í•´ì•¼ í•©ë‹ˆë‹¤.")

with col_end3:
    st.markdown("#### ğŸ¤ Partnership")
    st.caption("í•¨ê»˜ì˜ í˜")
    st.write("ë§ë²Œì´ëŠ” ë‚´ ì§‘ ë§ˆë ¨ ê¸°ê°„ì„ êµ¬ì¡°ì ìœ¼ë¡œ ë‹¨ì¶•ì‹œí‚µë‹ˆë‹¤.")

st.subheader("ğŸŒŸ ë‹¹ì‹ ì˜ ì‹œë‚˜ë¦¬ì˜¤ëŠ” ì§€ê¸ˆë¶€í„°ì…ë‹ˆë‹¤")

if st.button("ğŸš€ ë‚´ ì§‘ ë§ˆë ¨ ì‹œë‚˜ë¦¬ì˜¤ ì‹œì‘í•˜ê¸°"):
    st.balloons()
    st.success("ë°ì´í„°ë¥¼ ì´í•´í•œ ìˆœê°„, ì„ íƒì€ ì´ë¯¸ ë‹¬ë¼ì¡ŒìŠµë‹ˆë‹¤.")

st.divider()

# =========================
# 12) (4) í…Œì´ë¸”
# =========================
st.subheader(" ğŸ§¾ ì§‘ê³„ ë°ì´í„° í…Œì´ë¸”")

show_raw = st.checkbox("ì›ìë£Œ(ì†Œë“/ì•„íŒŒíŠ¸ ëŒ€í‘œê°’)ë„ ê°™ì´ ë³´ê¸°", value=True)

if show_raw:
    out = df[[
        "Year",
        "income_value",
        "income_monthly_won",
        "apt_price_median",
        "Income_Index",
        "Apartment_Index",
        "Purchasable_Pyeong",
        "Months_for_1Pyeong",
        "apt_price_col_used"
    ]].copy()

    out = out.rename(columns={
        "income_value": "ì†Œë“(value)",
        "income_monthly_won": "ì›”ì†Œë“(í™˜ì‚°)",
        "apt_price_median": "ì•„íŒŒíŠ¸(ì „êµ­ëŒ€í‘œ)_í‰ë‹¹ê°€ê²©",
        "Income_Index": "ì†Œë“ì§€ìˆ˜(2010=100)",
        "Apartment_Index": "ì•„íŒŒíŠ¸ì§€ìˆ˜(2010=100)",
        "Purchasable_Pyeong": "êµ¬ë§¤ê°€ëŠ¥í‰ìˆ˜(ì›”ì†Œë“/í‰ë‹¹)",
        "Months_for_1Pyeong": "1í‰êµ¬ë§¤_ê°œì›”ìˆ˜(í‰ë‹¹/ì›”ì†Œë“)",
        "apt_price_col_used": "ì•„íŒŒíŠ¸ê°€ê²©_ì»¬ëŸ¼"
    })
else:
    out = df[["Year", "Income_Index", "Apartment_Index", "Purchasable_Pyeong", "Months_for_1Pyeong"]].copy()

st.dataframe(out.set_index("Year"), use_container_width=True)


